{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('the-verdict.txt', <http.client.HTTPMessage at 0x13827ca4eb0>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "url = (\"https://raw.githubusercontent.com/rasbt/\"\n",
    "\"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
    "\"the-verdict.txt\")\n",
    "file_path = \"the-verdict.txt\"\n",
    "urllib.request.urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total no. of characters : 20479\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "with open(r\"C:\\Users\\ashmi\\Documents\\Artificial Intelligence\\Deep Learning\\Pytorch\\Learning Codes\\Deep learning\\PRACTICE\\Transformer\\GPT\\the-verdict.txt\",\"r\",encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "print(\"total no. of characters :\", len(text))\n",
    "print (text[:99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we best split this text to obtain a list of tokens? For this, we go on a small\n",
    "excursion and use Python’s regular expression library re for illustration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', '', ' ', 'world', ' ', '', '.', '', ' ', 'This', ' ', 'is', ' ', 'a', ' ', 'test', ' ', '', '?', '']\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "test= \"Hello, world . This is a test ?\"\n",
    "result = re.split(r'([,.:;?_!\"()\\']|--|\\s)', test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "r'([,.:;?_!\"()\\']|--|\\s) this is a computer experssion used to split all type of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4690\n"
     ]
    }
   ],
   "source": [
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "preprocessed = [item.strip() for item in preprocessed if item.strip()] #Removes unnecessary spaces from words and symbols. and Eliminates completely empty strings from the list.\n",
    "print(len(preprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
     ]
    }
   ],
   "source": [
    "print(preprocessed[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1130\n"
     ]
    }
   ],
   "source": [
    "all_words = sorted(set(preprocessed))\n",
    "vocab_size = len (all_words)\n",
    "print(vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\n",
      "\"\n",
      "'\n",
      "(\n",
      ")\n",
      ",\n",
      "--\n",
      ".\n",
      ":\n",
      ";\n",
      "?\n",
      "A\n",
      "Ah\n",
      "Among\n",
      "And\n",
      "Are\n",
      "Arrt\n",
      "As\n",
      "At\n",
      "Be\n",
      "Begin\n",
      "Burlington\n"
     ]
    }
   ],
   "source": [
    "vocab = {token :integer for integer , token in enumerate (all_words)}\n",
    "for i , item in enumerate (all_words):\n",
    "    print(item)\n",
    "    if i > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down how the line  \n",
    "\n",
    "```python\n",
    "vocab = {token: integer for integer, token in enumerate(all_words)}\n",
    "```\n",
    "\n",
    "works step by step.\n",
    "\n",
    "---\n",
    "\n",
    "### **Understanding the Components**\n",
    "This is a **dictionary comprehension** that constructs a dictionary (`vocab`) by iterating over `all_words` using `enumerate()`. The structure is:\n",
    "\n",
    "```python\n",
    "{key: value for value, key in enumerate(iterable)}\n",
    "```\n",
    "where:\n",
    "- **`token`** (key) is each item (word or symbol) in `all_words`.\n",
    "- **`integer`** (value) is the index assigned to each `token` by `enumerate()`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step-by-Step Execution**\n",
    "\n",
    "#### **1. `enumerate(all_words)`**\n",
    "The `enumerate()` function assigns an index (starting from 0) to each item in `all_words`.  \n",
    "\n",
    "For example, if:\n",
    "\n",
    "```python\n",
    "all_words = ['!', ',', '--', 'Hello', 'example', 'world']\n",
    "```\n",
    "Then:\n",
    "```python\n",
    "list(enumerate(all_words))\n",
    "# Output:\n",
    "[(0, '!'), (1, ','), (2, '--'), (3, 'Hello'), (4, 'example'), (5, 'world')]\n",
    "```\n",
    "Each word is paired with a unique index.\n",
    "\n",
    "#### **2. Dictionary Comprehension**\n",
    "The comprehension:\n",
    "\n",
    "```python\n",
    "{token: integer for integer, token in enumerate(all_words)}\n",
    "```\n",
    "- Iterates over each `(index, token)` pair from `enumerate(all_words)`.\n",
    "- Assigns each **token** as a dictionary **key** and its corresponding **index** as the **value**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Final Output**\n",
    "For `all_words = ['!', ',', '--', 'Hello', 'example', 'world']`,  \n",
    "the dictionary `vocab` will be:\n",
    "\n",
    "```python\n",
    "{\n",
    "    '!': 0,\n",
    "    ',': 1,\n",
    "    '--': 2,\n",
    "    'Hello': 3,\n",
    "    'example': 4,\n",
    "    'world': 5\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **How the Code Works Line by Line**\n",
    "1. `enumerate(all_words)` → Generates `(index, word)` pairs.\n",
    "2. `{token: integer for integer, token in enumerate(all_words)}` → Constructs a dictionary.\n",
    "3. Each **token** (word/symbol) becomes a **key** and its **index** becomes a **value**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Why is this Useful?**\n",
    "- Converts words into numerical IDs (important for NLP, text processing, machine learning).\n",
    "- Ensures a **consistent mapping** of words to numbers.\n",
    "- Efficient, as it avoids multiple loops and extra variables.\n",
    "\n",
    "Let me know if you need more clarification! 😊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleTokenizerV1:\n",
    "    def __init__ (self, vocab):\n",
    "        self.str_to_int= vocab\n",
    "        self.int_to_str ={i:s for s,i in vocab.items()}\n",
    "    def encode (self, text ):\n",
    "        preprocessed= re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed= [item.strip() for item in preprocessed if item.strip()]\n",
    "        ids= [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = simpleTokenizerV1(vocab)\n",
    "text = \"\"\"\"It's the last he painted, you know,\"\n",
    "Mrs. Gisburn said with pardonable pride.\"\"\"\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" It' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.\n"
     ]
    }
   ],
   "source": [
    "dec= tokenizer.decode(ids)\n",
    "print(dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "his Python code defines a class called `simpleTokenizerV1`, which functions as a **basic tokenizer**. It converts text into numerical representations (**encoding**) and converts numerical representations back into text (**decoding**). This is commonly used in **Natural Language Processing (NLP)** tasks.\n",
    "\n",
    "Let's break down the code **line by line** with an **example**.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Class Definition**\n",
    "```python\n",
    "class simpleTokenizerV1:\n",
    "```\n",
    "- Defines a **class** named `simpleTokenizerV1`.\n",
    "- A **class** is a blueprint for creating objects that can store data and perform operations on it.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Initializing the Tokenizer**\n",
    "```python\n",
    "def __init__(self, vocab):\n",
    "```\n",
    "- `__init__` is a **constructor** that runs when an object of this class is created.\n",
    "- `vocab` is a **dictionary** mapping words (tokens) to unique integer IDs.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "vocab = {'Hello': 0, ',': 1, 'world': 2, '!': 3}\n",
    "tokenizer = simpleTokenizerV1(vocab)\n",
    "```\n",
    "This initializes the tokenizer with a vocabulary where:\n",
    "- `\"Hello\"` → `0`\n",
    "- `\",\"` → `1`\n",
    "- `\"world\"` → `2`\n",
    "- `\"!\"` → `3`\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Creating String-to-Integer and Integer-to-String Mappings**\n",
    "```python\n",
    "self.str_to_int = vocab\n",
    "```\n",
    "- **Stores the input vocabulary (`vocab`)** in an instance variable called `str_to_int`.\n",
    "- This dictionary is used to convert words into numbers (**string → integer**).\n",
    "\n",
    "```python\n",
    "self.int_to_str = {i: s for s, i in vocab.items()}\n",
    "```\n",
    "- **Reverses the dictionary (`vocab.items()`)** to create a mapping from numbers to words (**integer → string**).\n",
    "- This allows us to convert numbers back to text during **decoding**.\n",
    "\n",
    "### Example Execution:\n",
    "```python\n",
    "vocab = {'Hello': 0, ',': 1, 'world': 2, '!': 3}\n",
    "tokenizer = simpleTokenizerV1(vocab)\n",
    "\n",
    "print(tokenizer.str_to_int)  \n",
    "# {'Hello': 0, ',': 1, 'world': 2, '!': 3}\n",
    "\n",
    "print(tokenizer.int_to_str)  \n",
    "# {0: 'Hello', 1: ',', 2: 'world', 3: '!'}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Encoding: Converting Text to Numbers**\n",
    "```python\n",
    "def encode(self, text):\n",
    "```\n",
    "- This function takes a **string (`text`)** and **converts it into a list of integers**.\n",
    "\n",
    "### **Step 1: Tokenizing the Text**\n",
    "```python\n",
    "preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
    "```\n",
    "- Uses `re.split()` (regular expressions) to **split text into words and punctuation**.\n",
    "- **Pattern**: `([,.?_!\"()\\']|--|\\s)`\n",
    "  - This splits on **spaces, punctuation, and special symbols**.\n",
    "  - The **punctuation is kept as separate tokens**.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "text = \"Hello, world!\"\n",
    "preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
    "print(preprocessed)\n",
    "# Output: ['Hello', ',', ' ', 'world', '!', '']\n",
    "```\n",
    "\n",
    "### **Step 2: Cleaning Up Tokens**\n",
    "```python\n",
    "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "```\n",
    "- Removes unnecessary spaces and empty strings from the token list.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "print(preprocessed)\n",
    "# Output: ['Hello', ',', 'world', '!']\n",
    "```\n",
    "\n",
    "### **Step 3: Converting Words to Numbers**\n",
    "```python\n",
    "ids = [self.str_to_int[s] for s in preprocessed]\n",
    "```\n",
    "- Replaces **each word/token with its corresponding number** using `self.str_to_int`.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "ids = [0, 1, 2, 3]\n",
    "```\n",
    "- `\"Hello\"` → `0`\n",
    "- `\",\"` → `1`\n",
    "- `\"world\"` → `2`\n",
    "- `\"!\"` → `3`\n",
    "\n",
    "### **Step 4: Returning the Encoded Output**\n",
    "```python\n",
    "return ids\n",
    "```\n",
    "- Returns the list of numbers.\n",
    "\n",
    "#### **Final Encoding Example**\n",
    "```python\n",
    "vocab = {'Hello': 0, ',': 1, 'world': 2, '!': 3}\n",
    "tokenizer = simpleTokenizerV1(vocab)\n",
    "\n",
    "text = \"Hello, world!\"\n",
    "encoded = tokenizer.encode(text)\n",
    "\n",
    "print(encoded)  \n",
    "# Output: [0, 1, 2, 3]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Decoding: Converting Numbers to Text**\n",
    "```python\n",
    "def decode(self, ids):\n",
    "```\n",
    "- This function **takes a list of numbers** and **converts them back into text**.\n",
    "\n",
    "### **Step 1: Convert Numbers to Words**\n",
    "```python\n",
    "text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "```\n",
    "- Uses `self.int_to_str` to **replace each number with its corresponding word/token**.\n",
    "- Joins the words with **spaces**.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "ids = [0, 1, 2, 3]\n",
    "text = \" \".join(['Hello', ',', 'world', '!'])\n",
    "print(text)\n",
    "# Output: \"Hello , world !\"\n",
    "```\n",
    "Notice that punctuation has spaces around it. We fix this in the next step.\n",
    "\n",
    "### **Step 2: Remove Extra Spaces Before Punctuation**\n",
    "```python\n",
    "text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "```\n",
    "- Uses **regular expressions (`re.sub`)** to remove **extra spaces before punctuation**.\n",
    "- **Pattern**: `\\s+([,.?!\"()\\'])`\n",
    "  - Matches **one or more spaces (`\\s+`)** before **punctuation**.\n",
    "  - **Replaces it with just the punctuation (`\\1`)**.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "text = \"Hello , world !\"\n",
    "text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "print(text)\n",
    "# Output: \"Hello, world!\"\n",
    "```\n",
    "\n",
    "### **Step 3: Return the Decoded Text**\n",
    "```python\n",
    "return text\n",
    "```\n",
    "- Returns the cleaned-up text.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Final Decoding Example**\n",
    "```python\n",
    "decoded_text = tokenizer.decode([0, 1, 2, 3])\n",
    "print(decoded_text)\n",
    "# Output: \"Hello, world!\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Final Summary**\n",
    "### **What This Class Does**\n",
    "✅ **Encodes text** (converts words into numbers).  \n",
    "✅ **Decodes numbers** (converts numbers back into text).  \n",
    "✅ **Handles punctuation correctly** (keeps it separate and removes unnecessary spaces).\n",
    "\n",
    "### **Example Usage**\n",
    "```python\n",
    "vocab = {'Hello': 0, ',': 1, 'world': 2, '!': 3}\n",
    "tokenizer = simpleTokenizerV1(vocab)\n",
    "\n",
    "# Encoding\n",
    "text = \"Hello, world!\"\n",
    "encoded = tokenizer.encode(text)\n",
    "print(encoded)  \n",
    "# Output: [0, 1, 2, 3]\n",
    "\n",
    "# Decoding\n",
    "decoded = tokenizer.decode(encoded)\n",
    "print(decoded)\n",
    "# Output: \"Hello, world!\"\n",
    "```\n",
    "\n",
    "This is a **basic tokenizer**, useful in NLP applications like text processing and machine learning. 🚀\n",
    "\n",
    "Let me know if anything needs more explanation! 😊\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can modify the tokenizer to use an <|unk|> token if it encounters a word that is\n",
    "not part of the vocabulary. This helps the LLM understand\n",
    "that although these text sources are concatenated for training, they are, in fact,\n",
    "unrelated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1132\n"
     ]
    }
   ],
   "source": [
    "all_tokens = sorted(list(set(preprocessed)))\n",
    "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "vocab = {token:integer for integer,token in enumerate(all_tokens)}\n",
    "print(len(vocab.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('younger', 1127)\n",
      "('your', 1128)\n",
      "('yourself', 1129)\n",
      "('<|endoftext|>', 1130)\n",
      "('<|unk|>', 1131)\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(list(vocab.items())[-5:]):\n",
    "  print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleTokenizerV2:\n",
    "    def __init__ (self, vocab):\n",
    "        self.str_to_int= vocab\n",
    "        self.int_to_str ={i:s for s,i in vocab.items()}\n",
    "    def encode (self, text ):\n",
    "        preprocessed= re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed= [item.strip() for item in preprocessed if item.strip()]\n",
    "        preprocessed = [item if item in self.str_to_int else \"<|unk|>\" for item in preprocessed] # replace the unknown words by unknown tokens\n",
    "        ids= [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        text = re.sub(r'\\s+([,.:;?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
     ]
    }
   ],
   "source": [
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "text3 = \" <|endoftext|> \".join((text1, text2))\n",
    "print(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = simpleTokenizerV2(vocab)\n",
    "print(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" It' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tokenizer.encode(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1131, 5, 355, 1126, 628, 975, 10, 1130, 55, 988, 956, 1131, 1131, 7]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken \n",
    "\n",
    "ext = (\n",
    "\"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
    "\"of someunknownPlace.\"\n",
    ")\n",
    "integers = tokenizer.encode(ext)\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|unk|>, do you like tea? <|endoftext|> In the sunlit <|unk|> <|unk|>.\n"
     ]
    }
   ],
   "source": [
    "strings = tokenizer.decode(integers)\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken  \n",
    "\n",
    "# Load and tokenize the text\n",
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")  \n",
    "enc_text = tokenizer.encode(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[323, 9749, 5678, 304, 264, 47625, 389, 279, 51768, 26919, 13, 320, 27831, 358, 4856, 3463, 433, 1053, 617, 1027, 22463, 477, 48606, 9456, 10227, 2673, 315, 813, 27025, 75857, 9210, 574, 1148, 279, 3278, 2663, 433, 13, 358, 649, 6865, 18083, 13, 480, 100242, 666, 24510, 313, 26301, 1566, 10780, 2503, 466, 313, 451, 501, 5620, 813, 653, 4711, 481, 671, 67, 20901, 13, 330, 2173, 3388, 433, 596, 2133, 311, 3708, 279, 907, 315, 856, 6945, 364, 3195, 709, 26, 719, 358, 1541, 956, 1781, 315, 430, 11, 4491, 13, 23194, 5721, 313, 1820, 4814, 311, 18925, 83, 374, 682, 358, 1781, 315, 1210, 578, 3492, 11, 389, 18083, 13, 666, 24510, 596, 23726, 11, 56016, 1202, 721, 5544, 62, 439, 3582, 814, 1051, 27000, 304, 459, 26762, 40136, 315, 41585, 13, 1628, 433, 574, 539, 1193, 279, 18083, 13, 666, 86, 826, 889, 60234, 291, 13, 24805, 539, 279, 59708, 32565, 689, 25611, 728, 11, 520, 279, 1566, 480, 3017, 263, 19853, 1501, 11, 10717, 757, 1603, 480, 285, 22464, 596, 330, 77119, 1773, 32842, 1, 311, 2019, 11, 449, 24014, 304, 1077, 6548, 25, 330, 1687, 4985, 539, 1427, 5304, 1202, 1093, 1578, 94770, 11649, 2556, 17206, 1555, 279, 94710, 315, 32565, 689, 596, 24014, 358, 6612, 3025, 311, 3663, 279, 2144, 449, 3312, 16348, 488, 13, 45773, 7762, 480, 285, 22464, 0, 578, 3278, 1047, 1903, 1461, 313, 275, 574, 27442, 430, 814, 1288, 60234, 1461, 13, 22395, 813, 1866, 1877, 17162, 69025, 1051, 6755, 11, 323, 304, 813, 1866, 6696, 20781, 264, 8309, 66206, 13, 21931, 80822, 30, 19292, 13, 1442, 433, 1051, 11, 279, 34662, 315, 279, 11003, 574, 38905, 10297, 555, 2697, 75430, 18878, 3258, 11, 889, 11, 304, 682, 1695, 10082, 11, 7263, 704, 304, 279, 73605, 264, 1633, 44877, 330, 677, 275, 3620, 1, 389, 7762, 313, 606, 315, 1884, 1501, 88, 9908, 71116, 449, 4288, 11156, 1385, 430, 358, 617, 6755, 320, 40, 2834, 956, 2019, 555, 8884, 8, 7863, 311, 480, 285, 22464, 596, 19354, 13, 1628, 779, 313, 26301, 9006, 1694, 14132, 6348, 7430, 511, 481, 313, 1820, 10430, 27115, 8636, 704, 11, 323, 11, 439, 18083, 13, 666, 24510, 1047, 19698, 11, 279, 3430, 315, 330, 38, 285, 22464, 82, 1, 4024, 709, 382, 2181, 574, 539, 12222, 2380, 1667, 3010, 430, 11, 304, 279, 3388, 315, 264, 2478, 5672, 6, 887, 2785, 389, 279, 51768, 26919, 11, 433, 15187, 10222, 311, 757, 311, 5895, 3249, 480, 285, 22464, 1047, 2728, 709, 813, 19354, 13, 1952, 22599, 11, 433, 2216, 574, 264, 61299, 3575, 13, 2057, 62742, 813, 7555, 1053, 617, 1027, 2288, 4228, 313, 26301, 6762, 274, 29163, 1047, 1027, 15164, 279, 2092, 580, 315, 5605, 430, 18083, 13, 480, 285, 22464, 1047, 330, 35031, 3640, 1461, 1523, 1210, 1789, 18083, 13, 480, 285, 22464, 313, 300, 1778, 313, 32345, 539, 25281, 12222, 7154, 264, 1060, 1306, 7762, 596, 9006, 1047, 1027, 4529, 13, 1102, 2643, 387, 430, 568, 1047, 12502, 1077, 313, 11536, 568, 15262, 813, 14553, 313, 28753, 568, 3287, 956, 1390, 311, 733, 389, 19354, 26, 719, 433, 1053, 617, 1027, 2653, 311, 12391, 430, 568, 1047, 2728, 709, 813, 19354, 1606, 568, 1047, 12502, 1077, 382, 2173, 3388, 11, 422, 1364, 1047, 539, 38247, 1461, 1523, 11, 1364, 1047, 18813, 11, 439, 9083, 25611, 728, 687, 2954, 11, 4745, 311, 330, 36069, 1461, 709, 75857, 32158, 1047, 539, 6197, 1461, 1203, 311, 279, 2593, 301, 13, 2057, 2231, 279, 15998, 1139, 813, 1450, 1578, 313, 12840, 264, 348, 2328, 369, 264, 7555, 0, 2030, 18083, 13, 480, 285, 22464, 9922, 311, 617, 834, 67, 2692, 433, 313, 438, 358, 6612, 433, 2643, 387, 7185, 311, 1505, 704, 3249, 382, 791, 951, 495, 683, 2324, 315, 279, 51768, 26919, 79018, 5196, 311, 1778, 32227, 14584, 1424, 7607, 26, 323, 3515, 11, 389, 856, 1648, 311, 46867, 58870, 11, 10791, 264, 40942, 315, 7762, 596, 9839, 3497, 14589, 7317, 2492, 1990, 279, 281, 1572, 11, 358, 1047, 7182, 65162, 270, 2544, 279, 1828, 1938, 382, 40, 1766, 279, 5743, 520, 15600, 24923, 872, 33552, 2442, 8016, 26, 323, 18083, 13, 480, 285, 22464, 596, 10788, 574, 779, 4173, 532, 430, 11, 304, 279, 72758, 5672, 11, 358, 11922, 433, 14134, 13, 1102, 574, 539, 430, 856, 3552, 434, 574, 330, 88657, 794, 389, 430, 1486, 358, 1436, 617, 2728, 9083, 25611, 728, 279, 77796, 32834, 5890, 13, 1102, 574, 1120, 1606, 1364, 574, 721, 1962, 62, 7185, 313, 333, 358, 1253, 387, 91047, 20262, 279, 17231, 313, 9210, 358, 1766, 1077, 779, 13, 1789, 7762, 11, 682, 813, 2324, 11, 1047, 1027, 23712, 555, 7185, 3278, 25, 814, 1047, 31087, 291, 813, 1989, 11, 433, 1047, 1027, 312, 1636, 304, 279, 4106, 37002, 315, 872, 1008, 2987, 13, 1628, 433, 574, 9093, 21745, 535, 311, 5296, 1148, 2515, 279, 330, 34854, 6147, 16975, 315, 25098, 4309, 488, 1, 320, 40, 12929, 9083, 25611, 728, 8, 574, 3515, 389, 1461, 382, 40, 617, 9932, 430, 18083, 13, 480, 285, 22464, 574, 9257, 26, 323, 433, 574, 7214, 78632, 1260, 430, 1077, 10177, 574, 60508, 505, 420, 53237, 264, 36301, 719, 12190, 24617, 13, 1102, 374, 11, 439, 264, 6037, 11, 279, 1274, 889, 88106, 3300, 889, 636, 1455, 704, 315, 433, 26, 323, 7762, 596, 26861, 79498, 315, 813, 7555, 596, 2466, 8335, 9147, 1461, 11, 449, 459, 11341, 315, 4832, 1695, 93008, 16490, 11, 311, 1380, 53314, 433, 1139, 6302, 315, 1989, 323, 19913, 13, 2057, 279, 15629, 11, 358, 2011, 923, 11, 568, 14958, 12309, 80008, 26, 719, 568, 574, 12096, 55383, 1437, 28143, 288, 323, 8223, 62655, 34457, 9364, 449, 264, 21934, 430, 76649, 279, 42853, 267, 5070, 382, 1, 25821, 596, 1193, 28391, 374, 311, 2231, 13444, 1139, 35855, 1359, 574, 832, 315, 279, 3944, 91269, 568, 17551, 1523, 4028, 279, 1369, 85, 417, 323, 15310, 315, 459, 506, 9383, 275, 989, 21489, 33073, 76269, 17203, 11, 994, 11, 389, 264, 3010, 1938, 11, 358, 1047, 1578, 1629, 927, 505, 46867, 58870, 26, 323, 18083, 13, 480, 285, 22464, 11, 387, 6605, 389, 1461, 11, 3779, 369, 856, 81869, 25, 330, 33731, 374, 779, 4411, 21301, 398, 16614, 311, 1475, 1376, 315, 13444, 2266, 85203, 7762, 0, 1102, 1047, 2744, 1027, 813, 25382, 311, 617, 3278, 2019, 1778, 2574, 315, 1461, 25, 279, 2144, 1288, 387, 743, 1523, 304, 1327, 1509, 367, 13, 3639, 17948, 757, 1457, 574, 430, 11, 369, 279, 1176, 892, 11, 568, 594, 16243, 279, 16630, 13, 358, 1047, 3970, 1461, 11, 779, 3629, 11, 293, 71805, 1234, 4528, 14121, 2142, 313, 16514, 433, 279, 16898, 45284, 5296, 430, 63354, 1124, 315, 872, 11427, 414, 30, 2360, 313, 2000, 11, 74544, 3403, 11, 433, 6244, 10186, 430, 568, 574, 21901, 315, 18083, 13, 480, 285, 22464, 313, 69, 2159, 3403, 539, 311, 1518, 1077, 32677, 488, 13, 1102, 574, 813, 1866, 32677, 488, 568, 9508, 311, 387, 289, 2910, 287, 1234, 313, 26301, 1866, 19451, 439, 459, 1665, 369, 7515, 8329, 323, 3709, 1137, 382, 46240, 25237, 11, 2533, 358, 3077, 523, 40458, 19354, 1274, 1541, 956, 2019, 430, 6392, 922, 757, 313, 20670, 2019, 433, 922, 33412, 2895, 58863, 1359, 574, 813, 1193, 8835, 11, 439, 568, 16392, 505, 279, 2007, 323, 357, 21621, 704, 8800, 279, 7160, 32735, 52578, 382, 40, 65657, 1306, 1461, 11, 17948, 555, 813, 1566, 3492, 13, 33412, 2895, 58863, 574, 11, 304, 2144, 11, 10671, 279, 893, 315, 279, 4545, 313, 300, 7762, 5678, 11, 832, 2643, 2231, 433, 11, 1047, 1027, 279, 893, 315, 279, 6596, 13, 578, 14992, 10255, 574, 1071, 311, 617, 14454, 5678, 520, 856, 4333, 596, 7693, 11, 323, 358, 31156, 422, 264, 259, 18177, 315, 80822, 1234, 6789, 279, 15629, 596, 26454, 671, 67, 20901, 13, 2030, 912, 313, 2000, 433, 574, 539, 12222, 1306, 430, 1567, 430, 279, 721, 25888, 17533, 11687, 62, 13633, 12, 9949, 1047, 22088, 311, 3113, 872, 330, 6600, 485, 645, 2266, 40, 6656, 311, 18083, 13, 480, 285, 22464, 11, 889, 1047, 40609, 291, 311, 3041, 264, 49629, 315, 13465, 311, 1077, 9575, 13327, 304, 279, 18397, 48840, 382, 77955, 721, 4752, 62, 568, 523, 40458, 19354, 7673, 358, 4691, 60845, 382, 8100, 9408, 1077, 61225, 449, 264, 13310, 315, 1695, 2902, 372, 21020, 13051, 382, 55005, 11, 568, 3250, 956, 721, 19553, 62, 311, 1457, 11, 499, 1440, 26, 323, 358, 1390, 1461, 311, 4774, 5678, 1359, 1364, 1071, 5115, 5042, 382, 40, 7111, 922, 279, 33236, 4251, 32476, 839, 3130, 11, 449, 1202, 721, 69, 309, 4618, 12, 65932, 62, 348, 2315, 40916, 279, 43076, 315, 279, 28639, 3824, 1091, 54499, 11, 323, 1202, 8223, 62655, 34457, 3347, 2053, 304, 36301, 54434, 14418, 382, 1, 10493, 568, 523, 40458, 813, 9364, 2288, 30, 358, 9167, 956, 3970, 264, 3254, 832, 304, 279, 3838, 2266, 32, 8275, 28601, 315, 22295, 28129, 18083, 13, 480, 285, 22464, 596, 1825, 1797, 10431, 13, 330, 2181, 596, 813, 27873, 27946, 88, 11, 499, 1440, 13, 1283, 2795, 814, 2351, 539, 5052, 311, 617, 922, 26, 568, 596, 3288, 1124, 682, 3201, 3734, 832, 313, 2465, 34133, 313, 438, 430, 358, 617, 311, 2567, 50007, 2266, 16366, 27873, 27946, 88, 313, 33731, 596, 27946, 88, 922, 813, 9364, 30, 3092, 41328, 574, 7982, 1093, 279, 21059, 5594, 1727, 13, 358, 1071, 24613, 300, 3210, 311, 856, 3552, 434, 25, 330, 40, 2011, 2216, 1518, 701, 34133, 11, 499, 1440, 2266, 8100, 65657, 704, 4661, 6935, 269, 7162, 520, 279, 52578, 1405, 1077, 10177, 11, 84244, 287, 304, 264, 28314, 291, 10716, 11, 1047, 13318, 264, 54774, 323, 15107, 279, 8690, 39149, 76196, 596, 2010, 1990, 813, 31624, 382, 56084, 11, 2586, 1418, 568, 596, 539, 3411, 1359, 1364, 1071, 11, 449, 264, 12835, 430, 6818, 311, 10477, 1077, 23418, 2136, 26, 323, 358, 8272, 1077, 1990, 279, 42390, 5867, 716, 1105, 315, 279, 14321, 11, 323, 709, 279, 7029, 32249, 449, 60661, 1824, 22983, 99401, 82, 54946, 4315, 19837, 520, 1855, 20948, 382, 644, 279, 5213, 76, 478, 9309, 315, 1077, 293, 3023, 13603, 11, 23442, 264, 2848, 7713, 315, 36301, 323, 39575, 6302, 11, 18799, 832, 315, 279, 11537, 61137, 73478, 2315, 11, 304, 279, 31352, 7515, 1974, 291, 4124, 13, 578, 17983, 21782, 315, 279, 4124, 2663, 709, 682, 480, 285, 22464, 596, 3347, 2268, 50329, 13, 480, 285, 22464, 24465, 1203, 279, 3321, 1824, 5757, 1771, 11, 7882, 16038, 264, 721, 73, 569, 6729, 486, 62, 2539, 315, 18718, 12657, 1604, 300, 11, 15753, 459, 6916, 79781, 3201, 11, 323, 1071, 25, 330, 2746, 499, 2559, 1618, 499, 649, 1120, 10299, 311, 1518, 433, 13, 358, 1047, 433, 927, 279, 26976, 301, 56964, 11, 719, 568, 8434, 956, 1095, 433, 4822, 2266, 9642, 313, 40, 1436, 1120, 10299, 311, 1518, 433, 313, 1820, 1176, 34133, 315, 7762, 596, 358, 1047, 3596, 1047, 311, 26800, 856, 6548, 927, 0, 34067, 814, 1047, 279, 2035, 315, 34662, 313, 37890, 279, 8792, 7090, 304, 264, 28639, 14071, 477, 721, 25888, 17533, 11687, 62, 13633, 48840, 11, 477, 264, 78856, 2593, 301, 9277, 779, 430, 433, 3952, 279, 3177, 1555, 54499, 315, 2362, 18732, 295, 1122, 1486, 13, 578, 810, 27946, 2035, 6244, 279, 6945, 2731, 26, 3686, 11, 439, 856, 6548, 14264, 53184, 311, 279, 4376, 18179, 11, 682, 279, 29683, 29600, 3782, 704, 313, 543, 279, 20365, 31767, 79187, 439, 6264, 582, 1385, 11, 279, 29862, 315, 23095, 307, 343, 7709, 555, 902, 11, 449, 1778, 4766, 18543, 10151, 11, 568, 9152, 311, 37098, 6666, 505, 279, 1972, 2626, 315, 279, 6945, 311, 1063, 5128, 25912, 33194, 315, 7872, 13, 18083, 13, 480, 285, 22464, 11, 32644, 264, 21277, 7479, 311, 990, 389, 313, 55857, 11, 439, 433, 1051, 11, 779, 40605, 279, 4092, 315, 1077, 1866, 6945, 313, 32345, 48907, 11937, 304, 459, 19018, 8547, 311, 279, 3113, 315, 420, 905, 13053, 84, 22828, 13, 578, 6945, 574, 832, 315, 7762, 596, 330, 4620, 478, 1359, 439, 813, 63698, 388, 1053, 617, 2231, 433, 313, 275, 15609, 11, 389, 813, 961, 11, 264, 55307, 315, 24569, 11, 264, 44385, 287, 315, 60764, 11, 264, 44463, 11, 610, 723, 2785, 323, 610, 2101, 11, 430, 31256, 832, 315, 279, 68124, 31717, 785, 596, 59560, 9045, 311, 12157, 264, 50876, 13, 1102, 2322, 11, 304, 2875, 11, 520, 1475, 1486, 279, 7631, 315, 17104, 5333, 311, 387, 24937, 330, 4620, 398, 1, 1606, 1364, 574, 19781, 315, 1694, 24937, 330, 95928, 398, 75857, 438, 3686, 539, 311, 9229, 459, 19670, 315, 279, 64550, 382, 12348, 596, 279, 1566, 568, 24937, 11, 499, 1440, 1359, 18083, 13, 480, 285, 22464, 1071, 449, 65268, 481, 22519, 13, 330, 791, 1566, 719, 832, 1359, 1364, 37065, 11937, 313, 1, 8248, 279, 1023, 3250, 956, 1797, 11, 1606, 568, 14763, 433, 2266, 1, 86842, 433, 7673, 358, 574, 922, 311, 1833, 709, 420, 31089, 994, 358, 6755, 264, 4579, 9710, 323, 5602, 7762, 5678, 389, 279, 12447, 382, 2170, 568, 14980, 1070, 11, 813, 6206, 304, 279, 30278, 315, 813, 9231, 85, 7870, 268, 23724, 11, 279, 15792, 14198, 17301, 315, 7013, 15753, 1203, 505, 813, 4251, 52354, 11, 813, 16025, 7160, 22464, 83, 54888, 18742, 654, 291, 555, 264, 15648, 430, 30831, 279, 10631, 315, 264, 659, 51817, 1748, 296, 26169, 1815, 11, 358, 6612, 311, 1148, 264, 8547, 568, 1047, 279, 1890, 4367, 439, 813, 9364, 313, 1820, 4367, 315, 3411, 28799, 261, 1109, 568, 574, 382, 16366, 7555, 65657, 520, 1461, 409, 10872, 1113, 398, 11, 719, 813, 6548, 46368, 3347, 1077, 311, 279, 34133, 382, 1, 12555, 13, 23194, 5721, 4934, 311, 1518, 433, 1359, 1364, 6137, 11, 439, 422, 3521, 985, 11937, 13, 1283, 70756, 813, 28004, 11, 2103, 37163, 382, 55005, 11, 23194, 5721, 1766, 757, 704, 1317, 4227, 1359, 568, 1071, 34504, 26, 1243, 11, 12579, 813, 6916, 1555, 10705, 25, 330, 29951, 323, 1518, 279, 2800, 315, 279, 3838, 2266, 1548, 8710, 433, 311, 757, 449, 264, 3169, 315, 50765, 46318, 22519, 25, 279, 9061, 12, 9949, 11, 279, 12365, 2442, 51725, 11, 279, 8679, 1824, 385, 5022, 11, 279, 61128, 261, 12, 1911, 288, 313, 543, 279, 6485, 15858, 7174, 315, 279, 90044, 596, 13018, 8752, 13, 1628, 15716, 856, 5895, 7318, 279, 3685, 35491, 568, 1071, 11, 21939, 704, 813, 15489, 264, 2697, 25, 330, 9642, 11, 358, 2216, 1541, 956, 1518, 1268, 1274, 10299, 311, 3974, 2085, 430, 2266, 11649, 313, 275, 574, 1120, 279, 842, 832, 2643, 617, 2291, 29412, 369, 1461, 13, 8442, 568, 574, 11, 1555, 433, 682, 323, 304, 34781, 315, 433, 682, 313, 300, 568, 1047, 1027, 1555, 11, 323, 304, 34781, 315, 11, 813, 9364, 313, 708, 44877, 11, 779, 35509, 11, 779, 834, 34002, 11, 430, 832, 1317, 291, 311, 16106, 704, 25, 330, 3513, 14091, 47365, 449, 701, 41308, 9135, 439, 3131, 832, 1047, 1317, 291, 311, 2019, 25, 330, 3513, 14091, 47365, 449, 701, 990, 17642, 4071, 11, 449, 279, 16106, 389, 856, 23726, 11, 856, 23842, 16654, 459, 16907, 1817, 382, 22244, 374, 856, 1866, 1208, 404, 1359, 568, 1071, 11, 6522, 757, 1139, 264, 6453, 14733, 3130, 520, 279, 842, 315, 279, 70240, 307, 40136, 13, 1102, 574, 9518, 323, 14198, 323, 514, 589, 727, 25, 912, 330, 81524, 5233, 912, 1437, 292, 7561, 31217, 582, 11, 7000, 315, 279, 3805, 315, 53004, 369, 39656, 304, 264, 6945, 17496, 313, 49532, 682, 11, 912, 3325, 1879, 315, 3596, 3515, 1027, 1511, 439, 264, 14356, 382, 791, 2144, 7263, 2162, 311, 757, 279, 10973, 1620, 488, 315, 7762, 596, 1464, 449, 813, 2362, 2324, 382, 92750, 956, 499, 3596, 294, 73291, 449, 6308, 904, 810, 7673, 358, 4691, 11, 2103, 3411, 922, 369, 264, 11917, 315, 1778, 5820, 382, 1, 27247, 1359, 568, 1071, 27851, 382, 1, 2244, 3090, 20024, 414, 313, 269, 1880, 28075, 12241, 16366, 16913, 6548, 14264, 5213, 11, 323, 813, 54888, 281, 5962, 264, 2697, 1234, 872, 44877, 7160, 22464, 382, 1, 27247, 1781, 315, 433, 11, 856, 25237, 12637, 313, 3852, 810, 1109, 422, 358, 4265, 2646, 24891, 264, 15998, 2266, 3112, 813, 16630, 3309, 757, 304, 264, 8381, 430, 568, 2646, 3463, 315, 4205, 775, 382, 40, 7882, 3201, 11, 31655, 3210, 49230, 555, 856, 16907, 18841, 26, 323, 439, 358, 6656, 11, 856, 8071, 11299, 389, 264, 2678, 6945, 3485, 279, 26976, 301, 56964, 313, 1820, 1193, 1665, 15061, 279, 14733, 38971, 7363, 6427, 315, 279, 3130, 382, 55005, 11, 555, 622, 1009, 9135, 358, 1071, 382, 2181, 574, 264, 26610, 315, 264, 1541, 798, 313, 276, 2362, 19781, 1541, 798, 11, 11509, 304, 279, 11422, 1234, 264, 7147, 382, 1, 1383, 622, 1009, 313, 64, 4610, 3023, 9135, 358, 39169, 382, 1548, 574, 21737, 26, 719, 358, 6612, 1461, 3345, 4920, 757, 11, 27027, 264, 2697, 6288, 382, 31437, 264, 5895, 0, 19332, 449, 264, 21030, 5238, 313, 8248, 389, 96049, 41582, 13, 1472, 18069, 38838, 11, 1405, 1550, 499, 636, 433, 12241, 1548, 19089, 14297, 25, 330, 50329, 13, 4610, 3023, 6688, 433, 311, 757, 2266, 1, 25797, 313, 40, 3287, 956, 1440, 499, 1524, 7020, 279, 4610, 3023, 82, 13, 1283, 574, 1778, 459, 4225, 95644, 1077, 1800, 2266, 7189, 3287, 956, 313, 83, 484, 1306, 13, 662, 662, 662, 3005, 3288, 369, 757, 311, 6308, 1461, 994, 568, 574, 5710, 2266, 39469, 568, 574, 5710, 30, 1472, 12241, 40, 2011, 617, 1095, 264, 2697, 2288, 1790, 1097, 1394, 1133, 12731, 1555, 856, 13051, 11, 369, 568, 19089, 449, 264, 409, 10872, 1113, 12835, 25, 330, 9642, 313, 32158, 596, 459, 25629, 4382, 783, 11, 499, 1440, 11, 18083, 13, 4610, 3023, 13, 6385, 1193, 4623, 574, 311, 617, 1461, 2884, 555, 264, 60423, 30581, 313, 1494, 11, 8009, 4610, 3023, 0, 3005, 3463, 433, 279, 2771, 267, 1648, 315, 66084, 287, 813, 63556, 313, 1073, 25957, 433, 389, 264, 4087, 94009, 586, 13, 1628, 520, 279, 4545, 358, 574, 721, 1820, 62, 60423, 30581, 2266, 1, 25797, 11, 8009, 4610, 3023, 313, 300, 499, 2019, 13, 15148, 721, 9210, 62, 813, 3925, 12241, 34728, 574, 813, 3925, 13, 3005, 11846, 304, 1461, 11, 58135, 1142, 304, 1461, 313, 269, 3463, 1364, 1550, 13, 2030, 1364, 7846, 956, 11984, 539, 311, 617, 682, 279, 13633, 12, 9949, 449, 1077, 13, 3005, 7846, 956, 11984, 279, 2144, 430, 11, 389, 767, 77, 11218, 2919, 11, 832, 1436, 2744, 636, 3221, 3403, 311, 1518, 813, 9364, 13, 45773, 5333, 0, 3005, 596, 1120, 264, 12569, 92441, 287, 369, 1023, 35603, 13, 4610, 3023, 374, 279, 1193, 4459, 358, 3596, 7020, 2266, 22336, 3596, 7020, 30, 2030, 499, 1120, 1071, 313, 1875, 38, 285, 22464, 1047, 264, 22999, 15648, 304, 813, 6548, 382, 55005, 11, 358, 7020, 1461, 11, 323, 568, 7020, 757, 313, 3323, 433, 7077, 1306, 568, 574, 5710, 2266, 40, 12504, 856, 7899, 31655, 3210, 13, 330, 4599, 1364, 3288, 369, 499, 12241, 58841, 313, 84270, 1672, 37864, 311, 279, 51705, 13, 3005, 4934, 1461, 38905, 10297, 313, 438, 555, 757, 17642, 1548, 32627, 1578, 11, 323, 22982, 1203, 813, 2010, 311, 1427, 709, 520, 279, 26610, 315, 279, 1541, 798, 13, 330, 3947, 1051, 2919, 994, 358, 7846, 956, 1427, 520, 430, 3245, 313, 92062, 956, 3663, 433, 13, 2030, 358, 9770, 7182, 311, 2231, 433, 1618, 26, 323, 1457, 433, 596, 64688, 757, 313, 66, 3149, 757, 13, 3011, 596, 279, 2944, 3249, 358, 1541, 956, 294, 73291, 904, 810, 11, 856, 25237, 23194, 5721, 26, 477, 4856, 4610, 3023, 5678, 374, 279, 2944, 2266, 2520, 279, 1176, 892, 856, 28747, 41328, 922, 856, 22489, 6656, 1139, 264, 6129, 12876, 311, 3619, 1461, 2731, 382, 7189, 6562, 499, 4265, 3371, 757, 1268, 433, 7077, 1359, 358, 1071, 382, 1548, 14980, 3411, 709, 520, 279, 26610, 11, 323, 4483, 51868, 1990, 813, 19779, 264, 36213, 568, 1047, 25565, 311, 3177, 13, 58801, 568, 6656, 9017, 757, 382, 7189, 4265, 4856, 1093, 311, 3371, 499, 313, 28753, 358, 3077, 2744, 24740, 499, 315, 781, 44661, 856, 990, 2266, 40, 1903, 264, 409, 10872, 1113, 31257, 11, 902, 568, 4277, 266, 2270, 449, 264, 1695, 2902, 372, 21020, 14362, 773, 382, 55005, 11, 358, 3287, 956, 2512, 264, 31107, 994, 358, 11846, 304, 7182, 313, 438, 1457, 433, 596, 459, 3779, 18623, 1990, 603, 17642, 1548, 32627, 10284, 11, 2085, 80096, 11, 323, 15753, 832, 315, 279, 5655, 6916, 11843, 4825, 4741, 13, 330, 3947, 25, 1304, 6261, 10882, 313, 438, 1618, 527, 279, 82215, 499, 1093, 2266, 1548, 9277, 1124, 520, 856, 46811, 323, 8738, 311, 40320, 709, 323, 1523, 279, 3130, 11, 23351, 1457, 323, 1243, 24923, 279, 6945, 382, 72059, 433, 7077, 30, 358, 649, 3371, 499, 304, 4330, 4520, 313, 438, 433, 3287, 956, 1935, 1790, 5129, 311, 3621, 13, 662, 662, 662, 358, 649, 6227, 1457, 1268, 14792, 323, 18949, 358, 574, 994, 358, 2751, 18083, 13, 4610, 3023, 596, 5296, 13, 5046, 3388, 11, 5655, 1523, 11, 358, 1047, 2744, 721, 66922, 62, 1070, 574, 912, 832, 1093, 1461, 313, 3323, 358, 1047, 8208, 449, 279, 4365, 11, 55212, 279, 13783, 46089, 21237, 922, 1461, 11, 12222, 358, 4376, 2751, 311, 1781, 568, 574, 264, 8060, 11, 832, 315, 279, 3169, 430, 527, 2163, 4920, 13, 3296, 622, 1009, 11, 323, 568, 721, 16514, 62, 2163, 4920, 313, 28753, 568, 1047, 2586, 311, 4822, 0, 578, 2800, 315, 603, 1047, 311, 1095, 13520, 387, 41323, 3235, 477, 733, 1234, 11, 719, 568, 574, 1579, 3485, 279, 1510, 313, 263, 96049, 41582, 11, 439, 499, 2019, 382, 56084, 11, 358, 4024, 1022, 311, 279, 3838, 304, 856, 1455, 90168, 20247, 313, 74303, 7882, 11, 10425, 44491, 757, 11, 520, 279, 1853, 437, 315, 8009, 4610, 3023, 596, 7076, 315, 8060, 1694, 79743, 555, 279, 27025, 315, 856, 19354, 1461, 0, 5046, 3388, 358, 8967, 311, 656, 279, 6945, 369, 4400, 313, 40, 3309, 18083, 13, 4610, 3023, 779, 994, 1364, 6137, 311, 357, 67699, 2555, 922, 1077, 19542, 13, 358, 6227, 3794, 1022, 264, 14814, 22941, 17571, 922, 279, 34662, 1694, 721, 6095, 62, 313, 2319, 11, 358, 574, 82660, 989, 11, 856, 25237, 23194, 5721, 0, 358, 574, 53004, 311, 7182, 1093, 832, 315, 856, 1866, 274, 29163, 382, 1, 12487, 358, 574, 4529, 709, 323, 2163, 7636, 449, 1461, 13, 358, 1047, 3288, 682, 856, 45660, 304, 12178, 11, 323, 358, 1047, 1193, 311, 743, 709, 279, 2593, 301, 323, 636, 311, 990, 13, 1283, 1047, 1027, 5710, 1193, 17510, 42117, 4207, 11, 323, 568, 8636, 15187, 11, 315, 4851, 8624, 11, 779, 430, 1070, 1047, 1027, 912, 33269, 990, 315, 19814, 313, 26301, 3663, 574, 2867, 323, 68622, 13, 358, 1047, 2322, 1461, 3131, 477, 11157, 11, 1667, 1603, 11, 323, 3463, 1461, 73521, 323, 67542, 88, 13, 4800, 358, 5602, 430, 568, 574, 33689, 382, 7189, 574, 16089, 520, 1176, 11, 449, 264, 16632, 37637, 24617, 25, 16089, 311, 617, 856, 1450, 389, 1778, 264, 364, 11760, 3238, 5112, 813, 15234, 2324, 76646, 2779, 434, 6137, 311, 7958, 757, 55641, 398, 313, 300, 358, 19857, 279, 2010, 304, 358, 6612, 439, 422, 568, 1051, 10307, 757, 656, 433, 13, 578, 37392, 574, 8272, 555, 279, 3463, 25, 422, 568, 721, 52898, 62, 10307, 757, 11, 1148, 1053, 568, 2019, 311, 856, 1648, 315, 3318, 30, 3092, 53572, 6137, 311, 733, 264, 2697, 8545, 313, 40, 6612, 23418, 323, 36218, 382, 1, 12805, 11, 994, 358, 7111, 709, 11, 358, 9508, 311, 1518, 264, 15648, 4920, 813, 3345, 18004, 819, 48788, 313, 300, 422, 568, 1047, 279, 6367, 11, 323, 1051, 60986, 5678, 555, 10168, 433, 1203, 505, 757, 13, 3011, 506, 33361, 660, 757, 2103, 810, 13, 578, 6367, 30, 8595, 11, 358, 1047, 264, 6367, 5922, 17510, 315, 813, 0, 358, 67822, 520, 279, 10247, 18742, 13610, 11, 323, 6818, 1063, 315, 856, 76813, 5808, 29862, 13, 2030, 814, 4745, 757, 11, 814, 1589, 26902, 13, 358, 5602, 430, 568, 5828, 956, 10307, 279, 1501, 88, 9660, 313, 40, 7846, 956, 64917, 813, 6666, 26, 568, 1120, 8774, 813, 6548, 389, 279, 2653, 47869, 1990, 13, 13266, 1051, 279, 6305, 358, 1047, 2744, 559, 14468, 291, 11, 477, 9960, 709, 449, 1063, 21078, 6308, 13, 1628, 1268, 568, 5602, 1555, 856, 15812, 2268, 7189, 7111, 709, 1578, 11, 323, 10791, 14254, 315, 430, 26610, 315, 279, 1541, 798, 21363, 389, 279, 7147, 3221, 813, 4950, 13, 5414, 7555, 3309, 757, 49043, 433, 574, 279, 1566, 3245, 568, 1047, 2884, 313, 4345, 264, 5296, 4529, 449, 264, 38839, 1450, 11, 994, 568, 574, 1523, 304, 60434, 15255, 42386, 505, 264, 3766, 4851, 3440, 13, 4702, 264, 5296, 0, 2030, 433, 10975, 813, 4459, 3925, 13, 2684, 527, 1667, 315, 8893, 88106, 1285, 42056, 304, 1475, 1584, 13, 362, 893, 889, 1047, 2064, 372, 449, 279, 1510, 1436, 2646, 617, 9687, 430, 42727, 709, 39823, 12943, 13, 662, 662, 6905, 7189, 6656, 1203, 311, 856, 990, 11, 323, 4024, 389, 92441, 287, 323, 296, 8512, 2785, 26, 1243, 358, 7111, 520, 279, 1541, 798, 1578, 13, 358, 5602, 430, 11, 994, 4610, 3023, 17551, 304, 279, 1176, 12943, 11, 568, 7020, 1120, 1148, 279, 842, 1053, 387, 13, 1283, 1047, 43890, 813, 3917, 11, 42101, 433, 11, 37680, 433, 13, 3277, 1047, 358, 2884, 430, 449, 904, 315, 856, 2574, 30, 2435, 19117, 956, 1027, 9405, 315, 757, 313, 40, 1047, 1120, 18306, 1124, 13, 662, 662, 6905, 46639, 526, 433, 11, 23194, 5721, 11, 449, 430, 3663, 10307, 757, 358, 7846, 956, 656, 2500, 12943, 13, 578, 14733, 8206, 574, 11, 358, 3287, 956, 1440, 1405, 311, 2231, 433, 313, 62, 40, 1047, 2646, 3967, 5056, 8442, 11, 449, 856, 274, 29163, 323, 856, 586, 11, 264, 1501, 88, 35732, 315, 12745, 9960, 709, 279, 2144, 313, 40, 1120, 22982, 6308, 1139, 872, 12580, 13, 662, 662, 662, 8489, 11, 6308, 574, 279, 832, 11298, 1884, 5710, 6548, 1436, 1518, 1555, 313, 4151, 7833, 311, 279, 2458, 60485, 41582, 30456, 13, 4418, 956, 499, 1440, 1268, 11, 304, 7556, 264, 7362, 4221, 11, 1524, 20236, 4501, 11, 832, 2795, 4376, 279, 892, 539, 1148, 832, 6944, 311, 719, 1148, 832, 649, 30, 8489, 313, 9210, 574, 279, 1648, 358, 24937, 26, 323, 439, 568, 11203, 1070, 323, 15746, 757, 11, 279, 3245, 814, 2663, 856, 364, 26522, 2428, 6, 29368, 1093, 264, 3838, 315, 7563, 13, 1283, 3287, 956, 21423, 261, 11, 499, 3619, 11, 8009, 4610, 3023, 313, 383, 1120, 11203, 1070, 30666, 10307, 11, 323, 389, 813, 23726, 11, 1555, 279, 18004, 48788, 11, 358, 9508, 311, 6865, 279, 3488, 25, 364, 11787, 499, 2771, 499, 1440, 1405, 499, 2351, 5108, 704, 87314, 27806, 358, 1436, 617, 24937, 430, 3663, 11, 449, 430, 3488, 389, 433, 11, 358, 1288, 617, 2884, 264, 2294, 3245, 13, 578, 1828, 12474, 3245, 574, 311, 1518, 430, 358, 7846, 956, 313, 438, 430, 21507, 574, 2728, 757, 13, 2030, 11, 14346, 11, 520, 430, 9568, 11, 23194, 5721, 11, 574, 1070, 4205, 389, 9578, 358, 8434, 956, 617, 2728, 311, 617, 4610, 3023, 13989, 1603, 757, 11, 323, 311, 6865, 1461, 2019, 25, 364, 2181, 596, 539, 2288, 3389, 313, 40, 3358, 1501, 499, 1268, 6, 1980, 12348, 721, 16514, 62, 2288, 3389, 313, 275, 1053, 617, 1027, 11, 1524, 422, 568, 4265, 1027, 13989, 13, 358, 19937, 709, 856, 45660, 11, 323, 4024, 1523, 323, 3309, 18083, 13, 4610, 3023, 13, 5046, 3388, 358, 3287, 956, 3371, 1077, 721, 9210, 62, 313, 275, 1053, 617, 1027, 18341, 311, 1077, 13, 358, 5042, 1071, 358, 7846, 956, 6308, 1461, 11, 430, 358, 574, 2288, 7882, 13, 3005, 4856, 15262, 279, 4623, 313, 32158, 596, 779, 24364, 0, 1102, 574, 430, 430, 1903, 1077, 3041, 757, 279, 1541, 798, 13, 2030, 1364, 574, 50136, 23268, 520, 539, 3794, 279, 34133, 313, 32158, 1550, 779, 1390, 1461, 364, 10655, 6, 555, 1063, 832, 1501, 88, 0, 2468, 1176, 358, 574, 16984, 1364, 8434, 956, 1095, 757, 1022, 313, 438, 520, 856, 289, 1220, 6, 842, 358, 12090, 2895, 58863, 13, 7566, 11, 433, 574, 358, 889, 3940, 2895, 58863, 25, 358, 3309, 18083, 13, 4610, 3023, 568, 574, 279, 364, 5065, 6, 893, 11, 323, 1364, 3309, 18570, 775, 11, 323, 779, 433, 2751, 311, 387, 837, 13, 662, 662, 662, 1628, 568, 24937, 4610, 3023, 2085, 289, 2910, 287, 26, 323, 1364, 18799, 279, 6945, 4315, 1077, 10177, 596, 2574, 13, 662, 662, 662, 1875, 1548, 1344, 2234, 5678, 1523, 304, 279, 6916, 79781, 3221, 10705, 11, 17551, 1203, 813, 2010, 11, 323, 57220, 10194, 813, 11977, 24923, 433, 11, 7111, 709, 520, 279, 6945, 3485, 279, 90151, 56964, 382, 7189, 1093, 311, 27555, 430, 4610, 3023, 5678, 1053, 617, 2728, 433, 311, 757, 11, 422, 568, 4265, 1027, 3025, 311, 2019, 1148, 568, 3463, 430, 1938, 2266, 3112, 11, 304, 4320, 311, 264, 3488, 358, 2231, 4376, 1474, 4842, 276, 2740, 313, 1, 11382, 1578, 7673, 568, 70939, 704, 13, 330, 4599, 279, 832, 3245, 430, 12716, 757, 12660, 3221, 1461, 374, 430, 358, 7020, 3403, 311, 5387, 1022, 12241, 1548, 14980, 709, 323, 17551, 813, 1450, 389, 856, 17308, 449, 264, 12835, 13, 330, 7456, 279, 51705, 315, 433, 374, 430, 358, 721, 309, 62, 2103, 19354, 313, 11536, 2895, 58863, 596, 3815, 433, 369, 757, 0, 578, 4610, 3023, 82, 2559, 7636, 11, 323, 3621, 3131, 313, 8248, 1070, 596, 912, 55367, 65383, 1057, 3169, 315, 1989, 1210]\n"
     ]
    }
   ],
   "source": [
    "enc_sample = enc_text[50:]\n",
    "print(enc_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [323, 9749, 5678, 304]\n",
      "y: [9749, 5678, 304, 264]\n"
     ]
    }
   ],
   "source": [
    "context_size= 4\n",
    "x= enc_sample[:context_size]\n",
    "y=enc_sample[1:context_size+1]\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y: {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[323] ----> 9749\n",
      "[323, 9749] ----> 5678\n",
      "[323, 9749, 5678] ----> 304\n",
      "[323, 9749, 5678, 304] ----> 264\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    print(context, \"---->\", desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self,txt,tokenizer, max_length,stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "        token_ids= tokenizer.encode(txt)\n",
    "        for i in range (0,len(token_ids)- max_length,stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Explanation of the Code:**\n",
    "\n",
    "This code defines a custom `Dataset` class (`GPTDatasetV1`) that prepares data for training a model like GPT (a language model). It uses a **sliding window approach** to create input–target pairs for next-word prediction.\n",
    "\n",
    "Let’s break it down step by step, especially focusing on how the **for loop** works.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Dataset Class Definition:**\n",
    "```python\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "```\n",
    "\n",
    "- `txt`: The raw text data that you want to use for training.\n",
    "- `tokenizer`: A tokenizer that converts the text into token IDs (integers).\n",
    "- `max_length`: The **maximum length** of each input sequence.\n",
    "- `stride`: The **stride** or step size by which the sliding window moves.\n",
    "\n",
    "The tokenizer converts the raw text (`txt`) into a list of **token IDs** (`token_ids`) using the `tokenizer.encode(txt)` function.\n",
    "\n",
    "For example, if `txt = \"The quick brown fox\"`, and after tokenization, `token_ids` might look like:\n",
    "```python\n",
    "[101, 2000, 303, 4567, 2345]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2. The For Loop - Creating Input-Target Pairs**\n",
    "```python\n",
    "for i in range(0, len(token_ids) - max_length, stride):\n",
    "    input_chunk = token_ids[i:i + max_length]\n",
    "    target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "    self.input_ids.append(torch.tensor(input_chunk))\n",
    "    self.target_ids.append(torch.tensor(target_chunk))\n",
    "```\n",
    "\n",
    "Let’s break this loop down:\n",
    "\n",
    "- **Range for the loop:**  \n",
    "  The loop iterates over the `token_ids` list in steps determined by `stride`.  \n",
    "  `range(0, len(token_ids) - max_length, stride)` means the loop will start at index `0` and go up to `len(token_ids) - max_length`, incrementing by `stride` each time.\n",
    "\n",
    "- **Why `len(token_ids) - max_length`?**  \n",
    "  We need to stop before reaching the end, to make sure we can still extract an entire chunk of `max_length` tokens.\n",
    "\n",
    "#### **Example:**  \n",
    "Let’s say `token_ids = [101, 2000, 303, 4567, 2345, 102]`, `max_length = 3`, and `stride = 1`.\n",
    "\n",
    "- The loop will start at index `0` and continue until `len(token_ids) - max_length` (i.e., `len(token_ids) - 3 = 3`). So, the loop will go over the indices `0, 1, 2`.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Inside the Loop:**\n",
    "Within the loop, two chunks are created: **input** and **target**.\n",
    "\n",
    "#### **a. Input Chunk:**\n",
    "```python\n",
    "input_chunk = token_ids[i:i + max_length]\n",
    "```\n",
    "\n",
    "- **Explanation:**  \n",
    "  This takes a slice of `token_ids` starting from index `i` to `i + max_length`. This slice represents the **input** for the model.\n",
    "  \n",
    "  For example, if `i = 0` and `max_length = 3`, `input_chunk` will be:\n",
    "  ```python\n",
    "  input_chunk = [101, 2000, 303]\n",
    "  ```\n",
    "\n",
    "#### **b. Target Chunk:**\n",
    "```python\n",
    "target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "```\n",
    "\n",
    "- **Explanation:**  \n",
    "  This takes a slice of `token_ids` from `i + 1` to `i + max_length + 1`. This slice represents the **target** (next token prediction) for the model.\n",
    "  \n",
    "  If `i = 0` and `max_length = 3`, `target_chunk` will be:\n",
    "  ```python\n",
    "  target_chunk = [2000, 303, 4567]\n",
    "  ```\n",
    "  Here, the **target** is always the next token after the input.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Storing the Chunks:**\n",
    "```python\n",
    "self.input_ids.append(torch.tensor(input_chunk))\n",
    "self.target_ids.append(torch.tensor(target_chunk))\n",
    "```\n",
    "\n",
    "- After creating the `input_chunk` and `target_chunk` for each iteration of the loop, both are converted into **PyTorch tensors** and **added to the lists** `self.input_ids` and `self.target_ids`.\n",
    "\n",
    "#### **Example:**  \n",
    "After the first iteration (if `i = 0`), the lists will look like this:\n",
    "```python\n",
    "self.input_ids = [tensor([101, 2000, 303])]\n",
    "self.target_ids = [tensor([2000, 303, 4567])]\n",
    "```\n",
    "\n",
    "The loop continues to generate new input–target pairs as it slides through the `token_ids` list.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Final Length of Dataset**\n",
    "```python\n",
    "def __len__(self):\n",
    "    return len(self.input_ids)\n",
    "```\n",
    "\n",
    "- This function returns the total number of input–target pairs (or data samples) in the dataset. The length is simply the length of `self.input_ids`, since each `input_ids` corresponds to a `target_ids`.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Get Item**\n",
    "```python\n",
    "def __getitem__(self, idx):\n",
    "    return self.input_ids[idx], self.target_ids[idx]\n",
    "```\n",
    "\n",
    "- This function defines how to access individual samples from the dataset. For a given index `idx`, it returns the corresponding **input** and **target** tensors.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example of How This Works:**\n",
    "\n",
    "Given the example:\n",
    "- `token_ids = [101, 2000, 303, 4567, 2345, 102]`\n",
    "- `max_length = 3`\n",
    "- `stride = 1`\n",
    "\n",
    "**The dataset will be built as follows:**\n",
    "\n",
    "1. **First Iteration (`i = 0`):**\n",
    "   - `input_chunk = [101, 2000, 303]`\n",
    "   - `target_chunk = [2000, 303, 4567]`\n",
    "   \n",
    "   `input_ids = [tensor([101, 2000, 303])]`\n",
    "   `target_ids = [tensor([2000, 303, 4567])]`\n",
    "\n",
    "2. **Second Iteration (`i = 1`):**\n",
    "   - `input_chunk = [2000, 303, 4567]`\n",
    "   - `target_chunk = [303, 4567, 2345]`\n",
    "   \n",
    "   `input_ids = [tensor([101, 2000, 303]), tensor([2000, 303, 4567])]`\n",
    "   `target_ids = [tensor([2000, 303, 4567]), tensor([303, 4567, 2345])]`\n",
    "\n",
    "3. **Third Iteration (`i = 2`):**\n",
    "   - `input_chunk = [303, 4567, 2345]`\n",
    "   - `target_chunk = [4567, 2345, 102]`\n",
    "   \n",
    "   `input_ids = [tensor([101, 2000, 303]), tensor([2000, 303, 4567]), tensor([303, 4567, 2345])]`\n",
    "   `target_ids = [tensor([2000, 303, 4567]), tensor([303, 4567, 2345]), tensor([4567, 2345, 102])]`\n",
    "\n",
    "The dataset will be created as a sequence of input–target pairs that can then be used for training a language model.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Points:**\n",
    "- The **for loop** is used to create input–target pairs using a **sliding window** approach.\n",
    "- **`stride`** controls how much the window moves (in our case, by 1 token each time).\n",
    "- The **input** is the current sequence of tokens, and the **target** is the sequence shifted by 1 position, predicting the next token.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me explain the line:\n",
    "```python\n",
    "for i in range(0, len(token_ids) - max_length, stride):\n",
    "```\n",
    "This line is part of the loop that iterates over the `token_ids` list using a sliding window approach. Let's break it down and explain exactly what it does, step by step.\n",
    "\n",
    "### **What the range does:**\n",
    "\n",
    "- **Start (`0`)**: The loop starts from index `0`, which is the beginning of the `token_ids` list.\n",
    "- **Stop (`len(token_ids) - max_length`)**: The loop stops before the index `len(token_ids) - max_length`. This is because you need to make sure that there are enough tokens left to create a full input chunk of size `max_length`. If the loop goes past this point, there wouldn't be enough tokens left to form a complete `max_length`-sized chunk, and you'd get an incomplete input-target pair.\n",
    "- **Step (`stride`)**: The loop will move forward by `stride` positions in each iteration. This allows the sliding window to move forward by more than one token at a time, which is useful for generating diverse input-target pairs.\n",
    "\n",
    "### **Why subtract `max_length` from `len(token_ids)`?**\n",
    "You want to create an input chunk of size `max_length`. If you reach a point where there are fewer than `max_length` tokens left in the sequence, you can't create a full chunk, so you stop the loop there.\n",
    "\n",
    "### **Example:**\n",
    "\n",
    "Let’s say we have the following `token_ids` and settings:\n",
    "```python\n",
    "token_ids = [101, 2000, 303, 4567, 2345, 102]\n",
    "max_length = 3\n",
    "stride = 1\n",
    "```\n",
    "\n",
    "### **Step-by-Step Explanation:**\n",
    "1. **Length of `token_ids`:**  \n",
    "   `len(token_ids)` is `6` (since there are 6 tokens).\n",
    "   \n",
    "   We need to stop at `len(token_ids) - max_length`, which is `6 - 3 = 3`. So, the loop will go up to index `3`, but not include it.\n",
    "\n",
    "2. **Range Function:**  \n",
    "   The range function will be `range(0, 3, 1)`. This means the loop will iterate over the indices `0, 1, 2`.\n",
    "\n",
    "3. **How the loop works:**  \n",
    "   - **First iteration (`i = 0`):**\n",
    "     - `input_chunk = token_ids[0:3] = [101, 2000, 303]`\n",
    "     - `target_chunk = token_ids[1:4] = [2000, 303, 4567]`\n",
    "   \n",
    "   - **Second iteration (`i = 1`):**\n",
    "     - `input_chunk = token_ids[1:4] = [2000, 303, 4567]`\n",
    "     - `target_chunk = token_ids[2:5] = [303, 4567, 2345]`\n",
    "   \n",
    "   - **Third iteration (`i = 2`):**\n",
    "     - `input_chunk = token_ids[2:5] = [303, 4567, 2345]`\n",
    "     - `target_chunk = token_ids[3:6] = [4567, 2345, 102]`\n",
    "   \n",
    "   The loop ends here because there are no more tokens to process when `i = 3` (the last valid index).\n",
    "\n",
    "### **Loop Iteration Breakdown:**\n",
    "\n",
    "- **First Iteration (`i = 0`)**:\n",
    "  - `input_chunk = [101, 2000, 303]`\n",
    "  - `target_chunk = [2000, 303, 4567]`\n",
    "\n",
    "- **Second Iteration (`i = 1`)**:\n",
    "  - `input_chunk = [2000, 303, 4567]`\n",
    "  - `target_chunk = [303, 4567, 2345]`\n",
    "\n",
    "- **Third Iteration (`i = 2`)**:\n",
    "  - `input_chunk = [303, 4567, 2345]`\n",
    "  - `target_chunk = [4567, 2345, 102]`\n",
    "\n",
    "So, the `stride = 1` means the sliding window moves forward **1 token at a time**.\n",
    "\n",
    "---\n",
    "\n",
    "### **General Formula:**\n",
    "\n",
    "- The loop is designed to create a sliding window of `max_length` tokens, and at each step, the `stride` determines how many tokens you skip forward before creating the next chunk. If `stride = 1`, the window moves forward by one token, while if `stride = 2`, it would skip ahead by two tokens after each iteration.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary:**\n",
    "\n",
    "- The **for loop** iterates over `token_ids` using a sliding window approach.\n",
    "- The range function ensures that the loop doesn't go past the point where a full chunk of `max_length` tokens can be taken.\n",
    "- **Stride** controls how far the sliding window moves in each iteration, and the loop generates pairs of **input** and **target** chunks for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt,batch_size,max_length=256, stride= 128, shuffle=True,drop_last=True,num_workers=0):\n",
    "   tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "   dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "   dataloader = DataLoader(dataset,batch_size=batch_size,shuffle=shuffle,drop_last=drop_last,num_workers=num_workers)\n",
    "   return dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n",
      "[tensor([[2885, 1464, 1807, 3619]]), tensor([[1464, 1807, 3619,  402]])]\n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "dataloader= create_dataloader_v1(raw_text, max_length=4,stride=2,shuffle=False,batch_size=1)\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "second_batch = next(data_iter)\n",
    "print(first_batch)\n",
    "print(second_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of the Process Described in the Passage:\n",
    "\n",
    "The passage is describing the process of converting **token IDs** into **embedding vectors** for training a GPT-like (decoder-only transformer) language model (LLM). This process is essential in NLP models, as it allows the model to work with dense, continuous vector representations instead of sparse, discrete token IDs. Here's a breakdown of the key concepts and steps involved:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Tokenization & Token IDs**:\n",
    "First, you start with some **raw text** that is tokenized using a **tokenizer** (such as BPE - Byte Pair Encoding). For example, let's say the sentence \"This is an example.\" is tokenized into token IDs, and the result might look like this:\n",
    "```\n",
    "Tokenized Text: [\"This\", \"is\", \"an\", \"example\", \".\"]\n",
    "Token IDs: [40134, 2052, 133, 389, 12]\n",
    "```\n",
    "\n",
    "- The tokenizer converts each word or symbol into a **unique integer ID**.\n",
    "  \n",
    "Now, these token IDs need to be converted into **embedding vectors** to allow the model to work with them effectively during training.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **What is an Embedding?**:\n",
    "An **embedding** is a continuous vector representation of a discrete object (in this case, a token). Instead of representing each token with just an integer ID (which is discrete), each token is represented as a vector in a continuous space. These vectors help the model capture semantic relationships between tokens.\n",
    "\n",
    "For example:\n",
    "- A token ID `3` could map to an embedding vector like `[ -0.4015, 0.9666, -1.1481 ]`.\n",
    "- A token ID `5` might map to `[ 1.2753, -0.2010, -0.1606 ]`.\n",
    "\n",
    "The key idea is that these embeddings provide a way to represent the token in a space where similar tokens are close to each other (in terms of their embedding vectors).\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Embedding Layer Initialization**:\n",
    "The process starts by initializing a **random embedding layer**. This layer is typically a matrix where:\n",
    "- Each **row** corresponds to the embedding of a specific token ID.\n",
    "- Each **column** corresponds to a dimension of the embedding vector (e.g., 3 dimensions, 5 dimensions, 12,288 dimensions, etc.).\n",
    "\n",
    "#### Example:\n",
    "Suppose you have a vocabulary of **6 tokens** and you want to create embeddings of size **3** (3-dimensional embeddings). The embedding layer would look like this:\n",
    "```\n",
    "Embedding Weight Matrix (size: 6 x 3):\n",
    "[ [ 0.3374, -0.1778, -0.1690],\n",
    "  [ 0.9178,  1.5810,  1.3010],\n",
    "  [ 1.2753, -0.2010, -0.1606],\n",
    "  [ -0.4015,  0.9666, -1.1481],\n",
    "  [ -1.1589,  0.3255, -0.6315],\n",
    "  [ -2.8400, -0.7849, -1.4096] ]\n",
    "```\n",
    "Here, we have **6 rows** (one for each token in the vocabulary), and each row has **3 columns** (embedding dimensions).\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Token ID Lookup**:\n",
    "When we want to look up the embedding of a token ID, we essentially perform a **lookup** in the embedding matrix.\n",
    "\n",
    "For example, to get the embedding for token ID `3`, we go to the 3rd row of the matrix (using zero-based indexing), which is:\n",
    "```\n",
    "[ -0.4015, 0.9666, -1.1481 ]\n",
    "```\n",
    "This is the **embedding vector** corresponding to token ID `3`.\n",
    "\n",
    "The process is akin to **one-hot encoding**, but instead of having a sparse vector (like `[0, 0, 1, 0, 0, 0]` for token ID `3`), we get a **dense, continuous vector** representing the token.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Looking Up Embeddings for Multiple Token IDs**:\n",
    "You can look up the embeddings for multiple token IDs in one step. For example, if you have a sequence of token IDs `[2, 3, 5, 1]`, and you pass them through the embedding layer:\n",
    "```python\n",
    "input_ids = torch.tensor([2, 3, 5, 1])\n",
    "embedding_layer(input_ids)\n",
    "```\n",
    "The result is a **4 x 3 matrix**:\n",
    "```\n",
    "tensor([[ 1.2753, -0.2010, -0.1606],\n",
    "        [-0.4015,  0.9666, -1.1481],\n",
    "        [-2.8400, -0.7849, -1.4096],\n",
    "        [ 0.9178,  1.5810,  1.3010]])\n",
    "```\n",
    "Each **row** in this matrix corresponds to the embedding vector for each token ID in the input sequence.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Embedding Layer as a Lookup**:\n",
    "The embedding layer in PyTorch acts as a **lookup table** for token IDs. Instead of encoding the tokens manually into vectors, we use this layer to retrieve the corresponding embedding for each token ID efficiently. As mentioned, this is essentially a more optimized form of one-hot encoding followed by a matrix multiplication in a fully connected layer.\n",
    "\n",
    "### Key Takeaways:\n",
    "1. **Embedding Vectors**: The embedding process converts discrete token IDs into continuous vectors that represent tokens in a high-dimensional space, capturing their semantic meaning.\n",
    "2. **Embedding Layer**: The embedding layer holds a matrix of token embeddings, with each row corresponding to a token's embedding vector.\n",
    "3. **Lookup Process**: Token IDs are mapped to their respective embedding vectors by looking up the corresponding row in the embedding matrix.\n",
    "4. **Training**: These embeddings are **randomly initialized** at the start of training and are updated during the backpropagation process to improve the model's ability to predict and understand relationships between tokens.\n",
    "\n",
    "---\n",
    "\n",
    "### Why is this Important?\n",
    "Embedding vectors are an essential part of training LLMs like GPT, as they allow the model to process text input more effectively. These embeddings help the model understand semantic relationships between tokens, allowing it to generate text and make predictions more accurately. During training, the embedding weights are optimized to capture better relationships between words, which improves the model's performance over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Embeddings Shape: torch.Size([8, 4, 256])\n",
      "Positional Embeddings Shape: torch.Size([8, 4, 256])\n",
      "Final Input Embeddings Shape: torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define vocabulary size and embedding dimensions\n",
    "vocab_size = 50257  # Vocabulary size from BPE tokenizer\n",
    "embedding_dim = 256  # Embedding dimension (realistic but smaller than GPT-3)\n",
    "context_length = 4   # Maximum sequence length (number of tokens per input)\n",
    "batch_size = 8       # Number of text samples per batch\n",
    "\n",
    "# Create the token embedding layer\n",
    "token_embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "# Create the positional embedding layer\n",
    "pos_embedding_layer = nn.Embedding(context_length, embedding_dim)\n",
    "\n",
    "# Simulated tokenized input (batch of token IDs)\n",
    "inputs = torch.randint(0, vocab_size, (batch_size, context_length))  # Random token IDs\n",
    "\n",
    "# Convert token IDs to embeddings\n",
    "token_embeddings = token_embedding_layer(inputs)  # Shape: (8, 4, 256)\n",
    "\n",
    "# Create positional encodings (same for all samples in batch)\n",
    "positional_indices = torch.arange(context_length).unsqueeze(0).repeat(batch_size, 1)\n",
    "pos_embeddings = pos_embedding_layer(positional_indices)  # Shape: (8, 4, 256)\n",
    "\n",
    "# Add positional embeddings to token embeddings\n",
    "input_embeddings = token_embeddings + pos_embeddings  # Shape: (8, 4, 256)\n",
    "\n",
    "# Print output shapes to verify\n",
    "print(\"Token Embeddings Shape:\", token_embeddings.shape)\n",
    "print(\"Positional Embeddings Shape:\", pos_embeddings.shape)\n",
    "print(\"Final Input Embeddings Shape:\", input_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Summary of This Section: Encoding Word Positions and Creating Input Embeddings**  \n",
    "\n",
    "1. **Token Embeddings**  \n",
    "   - The text is first tokenized into **token IDs**.  \n",
    "   - Each token ID is mapped to a **fixed-size vector** using an **embedding layer** in PyTorch.  \n",
    "   - This is like looking up a word in a dictionary and getting a unique numerical representation.\n",
    "\n",
    "2. **The Problem: No Positional Awareness**  \n",
    "   - The transformer model does not **naturally** understand the order of words.  \n",
    "   - For example, \"The cat sat\" and \"Sat cat the\" would look the same to the model.  \n",
    "   - This happens because each word gets the same embedding regardless of its position in the sentence.\n",
    "\n",
    "3. **Solution: Positional Embeddings**  \n",
    "   - To fix this, we add **positional embeddings** to token embeddings.  \n",
    "   - Each position in a sentence (1st, 2nd, 3rd, etc.) has a **unique** vector.  \n",
    "   - These vectors are learned during training.  \n",
    "   - By summing positional embeddings with token embeddings, the model now understands the order of words.\n",
    "\n",
    "4. **Implementation in Code**  \n",
    "   - We create a **token embedding layer** that maps token IDs to vectors.  \n",
    "   - We create a **positional embedding layer** that generates position-specific vectors.  \n",
    "   - The token embeddings and positional embeddings are **added together** to create **input embeddings**.  \n",
    "   - The final result is a **3D tensor (batch_size, sequence_length, embedding_size)** that is ready to be fed into a **GPT model**.\n",
    "\n",
    "### **Key Takeaways**\n",
    "✅ Token embeddings give meaning to words.  \n",
    "✅ Positional embeddings add order information.  \n",
    "✅ The sum of both embeddings becomes the **final input representation** for LLMs.  \n",
    "\n",
    "This ensures the model understands **both** the words and their **order in a sentence**. 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch: [tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n",
      "Second batch: [tensor([[2885, 1464, 1807, 3619]]), tensor([[1464, 1807, 3619,  402]])]\n",
      "Token Embeddings Shape: torch.Size([1, 4, 256])\n",
      "Positional Embeddings Shape: torch.Size([1, 4, 256])\n",
      "Final Input Embeddings Shape: torch.Size([1, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import torch\n",
    "import tiktoken  \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Download the text file\n",
    "url = (\"https://raw.githubusercontent.com/rasbt/\"\n",
    "       \"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
    "       \"the-verdict.txt\")\n",
    "file_path = \"the-verdict.txt\"\n",
    "urllib.request.urlretrieve(url, file_path)\n",
    "\n",
    "# Load and tokenize the text\n",
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")  \n",
    "enc_text = tokenizer.encode(raw_text)\n",
    "\n",
    "# Define a custom dataset class\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "# Function to create a DataLoader\n",
    "def create_dataloader_v1(txt, batch_size, max_length=256, stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
    "    return dataloader \n",
    "\n",
    "# Create DataLoader\n",
    "dataloader = create_dataloader_v1(raw_text, batch_size=1, max_length=4, stride=2, shuffle=False)\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "second_batch = next(data_iter)\n",
    "print(\"First batch:\", first_batch)\n",
    "print(\"Second batch:\", second_batch)\n",
    "\n",
    "# --- Adding Token and Positional Embeddings ---\n",
    "\n",
    "# Define token embedding layer\n",
    "vocab_size = 50257  # Typical size for GPT models\n",
    "embedding_dim = 256  # Example embedding size (GPT-3 uses 12,288)\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "# Convert token IDs into token embeddings\n",
    "token_embeddings = token_embedding_layer(first_batch[0])  # First batch of inputs\n",
    "print(\"Token Embeddings Shape:\", token_embeddings.shape)\n",
    "\n",
    "# Define positional embedding layer\n",
    "max_length = 4  # Same as the max sequence length\n",
    "pos_embedding_layer = torch.nn.Embedding(max_length, embedding_dim)\n",
    "\n",
    "# Generate position embeddings\n",
    "positions = torch.arange(max_length).unsqueeze(0)  # Create position indices\n",
    "pos_embeddings = pos_embedding_layer(positions)\n",
    "print(\"Positional Embeddings Shape:\", pos_embeddings.shape)\n",
    "\n",
    "# Combine token and positional embeddings\n",
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(\"Final Input Embeddings Shape:\", input_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **Explanation of What’s Happening in This Code**\n",
    "\n",
    "#### **1. Loading and Tokenizing the Text**\n",
    "- The text is downloaded from the internet and read into a variable.\n",
    "- A tokenizer converts the text into **token IDs** (numerical representations of words or subwords).\n",
    "\n",
    "#### **2. Creating a Dataset and DataLoader**\n",
    "- A custom `GPTDatasetV1` class is created, which:\n",
    "  - Splits the tokenized text into **fixed-length sequences**.\n",
    "  - Generates **input** and **target** sequences by shifting tokens by one position.\n",
    "- The `create_dataloader_v1()` function organizes these sequences into **batches**.\n",
    "\n",
    "#### **3. Generating Token Embeddings**\n",
    "- A **token embedding layer** is defined using `torch.nn.Embedding`.\n",
    "- This layer maps **token IDs** to **256-dimensional vectors**.\n",
    "- The first batch of token IDs is converted into embeddings.\n",
    "\n",
    "#### **4. Generating Positional Embeddings**\n",
    "- A **positional embedding layer** is created.\n",
    "- It maps **each position** (1st, 2nd, 3rd, etc.) in the sequence to a **256-dimensional vector**.\n",
    "- This ensures the model understands the order of tokens.\n",
    "\n",
    "#### **5. Combining Token and Positional Embeddings**\n",
    "- The **token embeddings** and **positional embeddings** are added together.\n",
    "- This forms the **final input embeddings**, which will be passed into a GPT model.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Takeaways**\n",
    "✅ **Token embeddings** give words a numerical representation.  \n",
    "✅ **Positional embeddings** add order information to the sequence.  \n",
    "✅ The sum of both creates **input embeddings**, which are the **final processed input** for an LLM.  \n",
    "\n",
    "This setup ensures that the model can **both understand the meaning of words** and **their order in a sentence**. 🚀\n",
    "\n",
    "The shape **`torch.Size([1, 4, 256])`** represents the dimensions of the **token embeddings tensor**, which consists of three parts:  \n",
    "\n",
    "1️⃣ **Batch size (`1`)**  \n",
    "   - This represents the number of sequences processed at once.  \n",
    "   - In this case, we are processing **one sequence** in the batch.  \n",
    "\n",
    "2️⃣ **Sequence length (`4`)**  \n",
    "   - This represents the number of tokens in the input sequence.  \n",
    "   - Each input sequence consists of **4 tokens** (since `max_length=4`).  \n",
    "\n",
    "3️⃣ **Embedding dimension (`256`)**  \n",
    "   - This represents the size of each token's embedding vector.  \n",
    "   - Each token is mapped to a **256-dimensional vector** in the embedding layer.  \n",
    "\n",
    "### **Example Breakdown**\n",
    "If the input token IDs were:\n",
    "```python\n",
    "tensor([[40, 367, 2885, 1464]])\n",
    "```\n",
    "- The batch contains **one sequence** (`1`).\n",
    "- There are **four tokens** in the sequence (`4`).\n",
    "- Each token is represented by a **256-dimensional vector** (`256`).\n",
    "\n",
    "---\n",
    "\n",
    "### **Intuition**  \n",
    "Each row in the tensor represents a **sequence** in the batch. Each column represents a **token** in the sequence. Each token is mapped to a **256-dimensional embedding vector** that encodes its meaning.  \n",
    "\n",
    "For a larger batch size (e.g., `batch_size=8`), the shape would be **`(8, 4, 256)`**, meaning we are processing 8 sequences simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
